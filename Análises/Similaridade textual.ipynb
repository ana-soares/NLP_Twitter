{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Similaridade textual.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"244ee7776b164ed094bc172229cf2781":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cd9d57ac8fec4835868a1ac41d8e23e4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_84b71ae60297473da21d700e07b5c927","IPY_MODEL_9b12b50c7bcf4657a08be005ea30c7f9"]}},"cd9d57ac8fec4835868a1ac41d8e23e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84b71ae60297473da21d700e07b5c927":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_80210669417749ff981b9c3ede1281d5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_faf6489baf3047cc84bb835c96dad684"}},"9b12b50c7bcf4657a08be005ea30c7f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3fda7d320f1c449982122e4b2520b619","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28/28 [54:38&lt;00:00, 117.10s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b43103c89b714504b33d3d786bda44c3"}},"80210669417749ff981b9c3ede1281d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"faf6489baf3047cc84bb835c96dad684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fda7d320f1c449982122e4b2520b619":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b43103c89b714504b33d3d786bda44c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"I685HBNNpS9b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595990694548,"user_tz":180,"elapsed":1180,"user":{"displayName":"Lucas Almada","photoUrl":"","userId":"05667266763048656725"}},"outputId":"6bc4fe43-52a2-4960-89d9-4acd1e48a9dc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DvzPymNIytJN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":570},"executionInfo":{"status":"ok","timestamp":1595990708825,"user_tz":180,"elapsed":11726,"user":{"displayName":"Lucas Almada","photoUrl":"","userId":"05667266763048656725"}},"outputId":"d317bd6e-fcd2-4e7c-a573-b5b184fd71f4"},"source":["!python -m spacy download pt\n","!pip install --upgrade tables"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pt_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz#egg=pt_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (49.1.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.7.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.6.20)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('pt_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n","You can now load the model via spacy.load('pt')\n","Requirement already up-to-date: tables in /usr/local/lib/python3.6/dist-packages (3.6.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.18.5)\n","Requirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CCu_2MZypb9O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1595990708831,"user_tz":180,"elapsed":11683,"user":{"displayName":"Lucas Almada","photoUrl":"","userId":"05667266763048656725"}},"outputId":"a6dd961a-e362-4848-f5fb-724983bc984c"},"source":["import pandas as pd\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords \n","import re\n","import spacy\n","from tqdm.notebook import tqdm\n","from sklearn.feature_extraction.text import CountVectorizer\n","import numpy as np\n","import dateutil\n","import seaborn as sns\n","from collections import OrderedDict, Counter\n","import os\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","from nltk import word_tokenize\n","import string\n","from datetime import datetime\n","import plotly.graph_objs as go"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jFKYCb38pmy1","colab_type":"code","colab":{}},"source":["df_tweet = pd.read_csv('/content/drive/My Drive/Projeto Ana/Utils/Análise 2020/tweets_total.csv', encoding = 'utf-8')\n","df_tweet = df_tweet.dropna()\n","\n","df_news = pd.read_csv('/content/drive/My Drive/Projeto Ana/Entrega_v1/Análise_Mídia/mediaframe_export.csv', encoding = 'utf-8')   \n","df_news = df_news.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZpLU3q4xqGle","colab_type":"code","colab":{}},"source":["def word_transform(words):\n","    words = words.split()\n","    total = [x.lower() for x in words]\n","    manual_list_stop_words = ['só','disse','ser','sobre','ainda','se','além', 'outros','porque','assim','ter', 'access_time', 'more_horiz',\n","                             'out','jun','publicado','diz','exame','patrocinado','ago','vip','abr','http','vai','HTTP'\n","                             'jul','jan','abr','set','nov','dez','conteúdo','mar','maio','estadão','marketing','pictwittercom','dia','mil','pra',\n","                             'fev','paulo', 'the','após', 'redação', 'foto', 'feira', 'segundo', 'nesta', 'sexta','contra','governo','dilma'\n","            'onde','pode','sábado','segunda','três', 'fazer','todos','parte','local', 'região', 'disse','quarta','nova','novo',\n","            'via','veja','neste','nm','aponta','mostra','rt','vejaabrilcombr','folha','vai','desde','do','multimidia','vejacom','blog', '-', '@','\"','...','dilma']\n","    stop_words = stopwords.words('portuguese')\n","    for i in manual_list_stop_words:\n","        stop_words.append(i)\n","    \n","    total = [x for x in total if x not in stop_words]\n","    total = [re.sub(r'[,\\.!?()]', '', x) for x in total]\n","    total = [x for x in total if not re.search(r\"\\d\", x)]\n","    \n","    long_string = (\" \").join(total)\n","    return long_string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oF2_220IqJ64","colab_type":"code","colab":{}},"source":["df_news['text'] = df_news['text'].apply(word_transform)\n","\n","df_tweet['tweet'] = df_tweet['tweet'].apply(word_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uosu23ifqvOB","colab_type":"code","colab":{}},"source":["df_news_work = df_news[['publication_date','text']]\n","df_news_work.columns = ['Data','Texto']\n","\n","df_tweet_work = df_tweet[['date','tweet']]\n","df_tweet_work.columns = ['Data','Tweet']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXamNQ8qr8Aa","colab_type":"code","colab":{}},"source":["df_tweet_work['Data'] = df_tweet_work['Data'].apply(lambda x: datetime.strptime(str(x), '%Y-%m-%d'))\n","df_tweet_work['Data'] = df_tweet_work['Data'].apply(lambda x: x.to_period('M'))\n","df_tweet_work['Data'] = df_tweet_work['Data'].apply(lambda x: x.to_timestamp())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FjAuek16rROt","colab_type":"code","colab":{}},"source":["def format_data(x):\n","  datetime_object = dateutil.parser.parse(x)\n","\n","  # formatar o datetime para o formato desejado (dia/mês/ano)\n","  dataFormatada = datetime_object.strftime(\"%d/%m/%Y\")\n","  return dataFormatada\n","\n","df_news_work['Data'] = df_news_work['Data'].apply(format_data)\n","df_news_work['Data'] = df_news_work['Data'].apply(lambda x: datetime.strptime(str(x), '%d/%m/%Y'))\n","df_news_work['Data'] = df_news_work['Data'].apply(lambda x: x.to_period('M'))\n","df_news_work['Data'] = df_news_work['Data'].apply(lambda x: x.to_timestamp())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3dmtXinEnWEX","colab_type":"code","colab":{}},"source":["df_news_work = df_news_work.groupby(['Data'])['Texto'].apply(' '.join).reset_index()\n","\n","df_tweet_work = df_tweet_work.groupby(['Data'])['Tweet'].apply(' '.join).reset_index()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Earf2DeRrpCI","colab_type":"code","colab":{}},"source":["df_total = pd.merge(df_news_work, df_tweet_work, on = ['Data'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRxBvxc9OvmV","colab_type":"code","colab":{}},"source":["#df_total.to_hdf('/content/drive/My Drive/Projeto Ana/Utils/Análise 2020/total_midia_tweet.hdf', key = 'hdf')\n","df_total=pd.read_hdf('/content/drive/My Drive/Projeto Ana/Utils/Análise 2020/total_midia_tweet.hdf', key = 'hdf')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zGO7Fae8j8E","colab_type":"code","colab":{}},"source":["nlp = spacy.load('pt')\n","nlp.max_length = 2800000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qBK0QNi915NJ","colab_type":"code","colab":{}},"source":["df_total = df_total.iloc[20:]\n","df_total = df_total.reset_index(drop = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-s7Gk99RHj_e","colab_type":"code","colab":{}},"source":["def sim(doc1, doc2):\n","  return doc1.similarity(doc2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImtDlKGt8usA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["244ee7776b164ed094bc172229cf2781","cd9d57ac8fec4835868a1ac41d8e23e4","84b71ae60297473da21d700e07b5c927","9b12b50c7bcf4657a08be005ea30c7f9","80210669417749ff981b9c3ede1281d5","faf6489baf3047cc84bb835c96dad684","3fda7d320f1c449982122e4b2520b619","b43103c89b714504b33d3d786bda44c3"]},"executionInfo":{"status":"ok","timestamp":1595988735887,"user_tz":180,"elapsed":989879,"user":{"displayName":"Lucas Almada","photoUrl":"","userId":"05667266763048656725"}},"outputId":"a6be386f-51ea-496b-d73e-e6853166a6a8"},"source":["array_2 = []\n","nlp_doc1 = None\n","nlp_doc2 = None\n","for i in tqdm(range(28)):\n","  doc1 = df_total['Tweet'].iloc[0:1].values[0]\n","  doc1 = doc1.split()[:100000]\n","  doc1 = ' '.join(doc1)\n","\n","  doc2 = df_total['Texto'].iloc[0:1].values[0]\n","  doc2 = doc2.split()[:100000]\n","  doc2 = ' '.join(doc2)\n","\n","  data = df_total['Data'].iloc[0:1].values[0]\n","\n","  doc1 = nlp(doc1)\n","  doc2 = nlp(doc2)\n","\n","  df_total = df_total.drop(df_total.index[[0]])\n","  df_total = df_total.reset_index(drop = True)\n","  sim = doc1.similarity(doc2)\n","\n","  del doc1\n","  del doc2\n","  \n","\n","\n"," \n","  array_2.append([data,sim])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"244ee7776b164ed094bc172229cf2781","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n","/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"I9h3A0GWEb_m","colab_type":"code","colab":{}},"source":["pd.DataFrame(array_2).to_csv(c)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zzMSjKSsXvhy","colab_type":"code","colab":{}},"source":["doc1 = df_total['Tweet'].iloc[0:1].values[0]\n","doc1 = doc1.split()[:500000]\n","doc1 = ' '.join(doc1)\n","\n","doc2 = df_total['Texto'].iloc[0:1].values[0]\n","doc2 = doc2.split()[:500000]\n","doc2 = ' '.join(doc2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWCaagFJDM8g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595983870319,"user_tz":180,"elapsed":21207,"user":{"displayName":"Lucas Almada","photoUrl":"","userId":"05667266763048656725"}},"outputId":"429a97cd-d711-423c-c833-95560f66d865"},"source":[" data = df_total['Data'].iloc[0:1].values[0]\n","\n","nlp_doc1 = nlp(doc1)\n","nlp_doc2 = nlp(doc2)\n","\n","df_total = df_total.drop(df_total.index[[0]])\n","df_total.reset_index(drop = True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Data</th>\n","      <th>Texto</th>\n","      <th>Tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2013-03-01</td>\n","      <td>retomada crescimento econômico somada maior us...</td>\n","      <td>» azenha: globo parecem estar perto vitória @i...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2013-04-01</td>\n","      <td>\"essa brecha criação partidos utilizada partid...</td>\n","      <td>alerta brasil: nazareno fonteles -o petista qu...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2013-05-01</td>\n","      <td>cimi levou conta outras ações registradas orga...</td>\n","      <td>@roxmo ano propôs acabar farra arrendamentos b...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2013-06-01</td>\n","      <td>deve voltar avaliar possibilidade pronunciamen...</td>\n","      <td>grandes decepções relação dilma retrocedemos r...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2013-07-01</td>\n","      <td>ex-governador josé serra psdb afirmou tarde de...</td>\n","      <td>escândalo tucano pipocando galera demonizando ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2013-08-01</td>\n","      <td>falcatruas liquidação banco rural rural nome l...</td>\n","      <td>andar carruagem faltara cela especial ex-integ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2013-09-01</td>\n","      <td>brasília banco central bc pessimista crescimen...</td>\n","      <td>“a espionagem nsa grave resposta ineficaz” @di...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2013-10-01</td>\n","      <td>globo tamanho texto brasília trânsito livre pa...</td>\n","      <td>pessoal apoia começa coçar cabeça verem luz ve...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2013-11-01</td>\n","      <td>processo interrompido eleição pt limitou mante...</td>\n","      <td>explicado contrato ibope r$ milhões única estr...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2013-12-01</td>\n","      <td>reportagem jornal nacional tv globo jose eugen...</td>\n","      <td>@edvaledval: retrospectiva desaprovação saúde ...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2014-01-01</td>\n","      <td>maiores acontecimentos economia global graves ...</td>\n","      <td>“@racionaiscltou: prometeu pá coisa cumpriu na...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2014-02-01</td>\n","      <td>presidente avisou janeiro davos suíça desta ve...</td>\n","      <td>#dilma recuou dar aumento médicos cubanos ment...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>2014-03-01</td>\n","      <td>ex-presidente fernando henrique cardoso critic...</td>\n","      <td>@alvarodias_ olho assalto #petrobras #transpar...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>2014-04-01</td>\n","      <td>quinta-feira fundo monetário internacional div...</td>\n","      <td>@naldovalenca @msnigres @taddei_piratini @indi...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2014-05-01</td>\n","      <td>brasília ministro previdência garibaldi alves ...</td>\n","      <td>@bosco_ferreira começou cobrar apoio padilha m...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>2014-06-01</td>\n","      <td>abafar coro “volta lula” pt oficializar candid...</td>\n","      <td>#crescimento: #dilma supera marca milhões #emp...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>2014-07-01</td>\n","      <td>presidente rousseff reiterou segunda-feira com...</td>\n","      <td>denúncia: sbt afirma contrato milionário ibope...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>2014-08-01</td>\n","      <td>avaliação positiva presidente rousseff oscilou...</td>\n","      <td>ninguém culpa tá sendo aprovadoeu hein desculp...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>2014-09-01</td>\n","      <td>\"meu compromisso meta inflação\" presidente que...</td>\n","      <td>@boyarinators marina brasileira premiada inter...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>2014-10-01</td>\n","      <td>pacote estímulo tributário implementado soment...</td>\n","      <td>@_jukeboxhero sim “@enunomura: suspende anúnci...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>2014-11-01</td>\n","      <td>petrolão política externa agora eua intermédio...</td>\n","      <td>brasil repassou us$ bilhões ditaduras comunist...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>2014-12-01</td>\n","      <td>escândalo precedentes história companhia brasi...</td>\n","      <td>dr italo gomes: expectativas rousseff logo vit...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>2015-01-01</td>\n","      <td>ex-diretor área internacional petrobras nestor...</td>\n","      <td>manifestação hoje dilma destaque imprensa vend...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>2015-02-01</td>\n","      <td>pompa dava tom daquele momento amparado popula...</td>\n","      <td>\"@reinaldoazevedo: sai defesa razão medidas di...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>2015-03-01</td>\n","      <td>alguns têm projeção quanto conta contribuinte ...</td>\n","      <td>\"@cleidelessnau: @blogdopim encabeçar própria ...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>2015-04-01</td>\n","      <td>hoje espírito menos corrosivo otimista diria m...</td>\n","      <td>@betoalbuquerque neocleptocral responsável úni...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>2015-05-01</td>\n","      <td>enquanto rousseff pt tentam enfrentar pauta co...</td>\n","      <td>luís inácio adams fala pedaladas fiscais #énot...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>2015-06-01</td>\n","      <td>viagem presidente rousseff fará estados unidos...</td>\n","      <td>cni divulga pesquisa ibope avaliação @blogdafo...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>2015-07-01</td>\n","      <td>conversa povo ex-presidente lulla saiu defesa ...</td>\n","      <td>aécio: ‘o habituou mentira’ http://lnis/uolcom...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>2015-08-01</td>\n","      <td>grupos manifestantes ligados centrais sindicai...</td>\n","      <td>fiquemos atentos: desistiu cpmf tentar novo … ...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>2015-09-01</td>\n","      <td>jovens negros pobres sendo caçados ônibus milí...</td>\n","      <td>intelectuais pró-pt criticam ajuste fiscal htt...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>2015-10-01</td>\n","      <td>linha tênue lobby feito empresas privadas exec...</td>\n","      <td>#politicacomoeuavejo mínima chance eventual re...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>2015-11-01</td>\n","      <td>direitistas convicção somente pequena daquilo ...</td>\n","      <td>política: admite quebrado paralisar máquina pú...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>2015-12-01</td>\n","      <td>brasília deflagração impeachment rousseff deve...</td>\n","      <td>#estudiogaucha hoje pagou pedaladas enfraquece...</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>2016-01-01</td>\n","      <td>secretário municipal saúde alexandre padilha u...</td>\n","      <td>roubar merenda criancinha entende cima perdoa ...</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>2016-02-01</td>\n","      <td>desculpa esfarrapada nilo batista responsável ...</td>\n","      <td>confirma \"porquinho\" petista josé eduardo card...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>2016-03-01</td>\n","      <td>ex-presidente luiz inácio lula silva chegar re...</td>\n","      <td>vergonha une lembro ir protesta dilma porém hj...</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>2016-04-01</td>\n","      <td>‘economia vive hemorragia’ “a continuidade ext...</td>\n","      <td>escondidinho sob nome constrana utc d ricardo ...</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>2016-05-01</td>\n","      <td>brasília principais articuladores formação bas...</td>\n","      <td>crime crime falta dilma dona janaína pascoal t...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>2016-06-01</td>\n","      <td>ministro supremo tribunal federal teori zavasc...</td>\n","      <td>tá agendado semana vem algo faço dilma @pastor...</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>2016-07-01</td>\n","      <td>relator-geral lei diretrizes orçamentárias ldo...</td>\n","      <td>ato brasília enterro simbólico ‘parabéns’ moro...</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>2016-08-01</td>\n","      <td>polícia federal comprovou denúncia ex-diretor ...</td>\n","      <td>nao passava fome faculdade governos russo chin...</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>2016-09-01</td>\n","      <td>brasília saber segunda-feira secretário execut...</td>\n","      <td>pq mijava dinheiro né hahahhaha bobão pause me...</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>2016-10-01</td>\n","      <td>críticas forma atuação posicionamentos polític...</td>\n","      <td>pobres viviam paraíso hein sakanada rei texto-...</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>2016-11-01</td>\n","      <td>alagoano floriano peixoto marechal austero fã ...</td>\n","      <td>boa todo câmara  incluindo aliados toda vida p...</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>2016-12-01</td>\n","      <td>nomes fortes sucessão presidente michel temer ...</td>\n","      <td>venha papinho q fizeram tal coisa porra nenhum...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Data  ...                                              Tweet\n","0  2013-03-01  ...  » azenha: globo parecem estar perto vitória @i...\n","1  2013-04-01  ...  alerta brasil: nazareno fonteles -o petista qu...\n","2  2013-05-01  ...  @roxmo ano propôs acabar farra arrendamentos b...\n","3  2013-06-01  ...  grandes decepções relação dilma retrocedemos r...\n","4  2013-07-01  ...  escândalo tucano pipocando galera demonizando ...\n","5  2013-08-01  ...  andar carruagem faltara cela especial ex-integ...\n","6  2013-09-01  ...  “a espionagem nsa grave resposta ineficaz” @di...\n","7  2013-10-01  ...  pessoal apoia começa coçar cabeça verem luz ve...\n","8  2013-11-01  ...  explicado contrato ibope r$ milhões única estr...\n","9  2013-12-01  ...  @edvaledval: retrospectiva desaprovação saúde ...\n","10 2014-01-01  ...  “@racionaiscltou: prometeu pá coisa cumpriu na...\n","11 2014-02-01  ...  #dilma recuou dar aumento médicos cubanos ment...\n","12 2014-03-01  ...  @alvarodias_ olho assalto #petrobras #transpar...\n","13 2014-04-01  ...  @naldovalenca @msnigres @taddei_piratini @indi...\n","14 2014-05-01  ...  @bosco_ferreira começou cobrar apoio padilha m...\n","15 2014-06-01  ...  #crescimento: #dilma supera marca milhões #emp...\n","16 2014-07-01  ...  denúncia: sbt afirma contrato milionário ibope...\n","17 2014-08-01  ...  ninguém culpa tá sendo aprovadoeu hein desculp...\n","18 2014-09-01  ...  @boyarinators marina brasileira premiada inter...\n","19 2014-10-01  ...  @_jukeboxhero sim “@enunomura: suspende anúnci...\n","20 2014-11-01  ...  brasil repassou us$ bilhões ditaduras comunist...\n","21 2014-12-01  ...  dr italo gomes: expectativas rousseff logo vit...\n","22 2015-01-01  ...  manifestação hoje dilma destaque imprensa vend...\n","23 2015-02-01  ...  \"@reinaldoazevedo: sai defesa razão medidas di...\n","24 2015-03-01  ...  \"@cleidelessnau: @blogdopim encabeçar própria ...\n","25 2015-04-01  ...  @betoalbuquerque neocleptocral responsável úni...\n","26 2015-05-01  ...  luís inácio adams fala pedaladas fiscais #énot...\n","27 2015-06-01  ...  cni divulga pesquisa ibope avaliação @blogdafo...\n","28 2015-07-01  ...  aécio: ‘o habituou mentira’ http://lnis/uolcom...\n","29 2015-08-01  ...  fiquemos atentos: desistiu cpmf tentar novo … ...\n","30 2015-09-01  ...  intelectuais pró-pt criticam ajuste fiscal htt...\n","31 2015-10-01  ...  #politicacomoeuavejo mínima chance eventual re...\n","32 2015-11-01  ...  política: admite quebrado paralisar máquina pú...\n","33 2015-12-01  ...  #estudiogaucha hoje pagou pedaladas enfraquece...\n","34 2016-01-01  ...  roubar merenda criancinha entende cima perdoa ...\n","35 2016-02-01  ...  confirma \"porquinho\" petista josé eduardo card...\n","36 2016-03-01  ...  vergonha une lembro ir protesta dilma porém hj...\n","37 2016-04-01  ...  escondidinho sob nome constrana utc d ricardo ...\n","38 2016-05-01  ...  crime crime falta dilma dona janaína pascoal t...\n","39 2016-06-01  ...  tá agendado semana vem algo faço dilma @pastor...\n","40 2016-07-01  ...  ato brasília enterro simbólico ‘parabéns’ moro...\n","41 2016-08-01  ...  nao passava fome faculdade governos russo chin...\n","42 2016-09-01  ...  pq mijava dinheiro né hahahhaha bobão pause me...\n","43 2016-10-01  ...  pobres viviam paraíso hein sakanada rei texto-...\n","44 2016-11-01  ...  boa todo câmara  incluindo aliados toda vida p...\n","45 2016-12-01  ...  venha papinho q fizeram tal coisa porra nenhum...\n","\n","[46 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"3sAVTUw-Dnhc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1595983958799,"user_tz":180,"elapsed":569,"user":{"displayName":"Lucas Almada","photoUrl":"","userId":"05667266763048656725"}},"outputId":"66d054a2-6847-4366-f55b-58985cb0e742"},"source":["nlp_doc1.similarity(nlp_doc2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/runpy.py:193: ModelsWarning:\n","\n","[W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.9549698890325325"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"PG9ISBjoX3El","colab_type":"code","colab":{}},"source":["df1 = pd.read_csv('/content/drive/My Drive/Projeto Ana/Utils/Análise 2020/2014-09_similaridade.csv')\n","df2 = pd.read_csv('/content/drive/My Drive/Projeto Ana/Utils/Análise 2020/2014-08_similaridade.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wd0vlizs9fg3","colab_type":"code","colab":{}},"source":["df_total = pd.concat([df2,df1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mC_SorBleFKA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595990933911,"user_tz":180,"elapsed":1096,"user":{"displayName":"Lucas Almada","photoUrl":"","userId":"05667266763048656725"}},"outputId":"fdfcfd36-1230-4f0c-8492-8376411db68f"},"source":["df_total"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2014-09-01</td>\n","      <td>0.954463</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2014-10-01</td>\n","      <td>0.973430</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2014-11-01</td>\n","      <td>0.967619</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2014-12-01</td>\n","      <td>0.966987</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2015-01-01</td>\n","      <td>0.969573</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>2015-02-01</td>\n","      <td>0.963006</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>2015-03-01</td>\n","      <td>0.955877</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>2015-04-01</td>\n","      <td>0.964053</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>2015-05-01</td>\n","      <td>0.973276</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>2015-06-01</td>\n","      <td>0.965090</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>2015-07-01</td>\n","      <td>0.960453</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>2015-08-01</td>\n","      <td>0.967825</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>2015-09-01</td>\n","      <td>0.966486</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>2015-10-01</td>\n","      <td>0.978070</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>2015-11-01</td>\n","      <td>0.971703</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>2015-12-01</td>\n","      <td>0.972356</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>2016-01-01</td>\n","      <td>0.972522</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>2016-02-01</td>\n","      <td>0.959797</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>2016-03-01</td>\n","      <td>0.958413</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>2016-04-01</td>\n","      <td>0.975944</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>20</td>\n","      <td>2016-05-01</td>\n","      <td>0.972383</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>2016-06-01</td>\n","      <td>0.975523</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>22</td>\n","      <td>2016-07-01</td>\n","      <td>0.969961</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>23</td>\n","      <td>2016-08-01</td>\n","      <td>0.974454</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>24</td>\n","      <td>2016-09-01</td>\n","      <td>0.973805</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>25</td>\n","      <td>2016-10-01</td>\n","      <td>0.980590</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>26</td>\n","      <td>2016-11-01</td>\n","      <td>0.977438</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>27</td>\n","      <td>2016-12-01</td>\n","      <td>0.960286</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2013-01-01</td>\n","      <td>0.964434</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2013-02-01</td>\n","      <td>0.958117</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2013-03-01</td>\n","      <td>0.957099</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2013-04-01</td>\n","      <td>0.962764</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2013-05-01</td>\n","      <td>0.968763</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>2013-06-01</td>\n","      <td>0.965812</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>2013-07-01</td>\n","      <td>0.963463</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>2013-08-01</td>\n","      <td>0.960850</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>2013-09-01</td>\n","      <td>0.960586</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>2013-10-01</td>\n","      <td>0.968932</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>2013-11-01</td>\n","      <td>0.959499</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>2013-12-01</td>\n","      <td>0.955507</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>2014-01-01</td>\n","      <td>0.965953</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>2014-02-01</td>\n","      <td>0.960077</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>2014-03-01</td>\n","      <td>0.956442</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>15</td>\n","      <td>2014-04-01</td>\n","      <td>0.960666</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>16</td>\n","      <td>2014-05-01</td>\n","      <td>0.964631</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>17</td>\n","      <td>2014-06-01</td>\n","      <td>0.952294</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>18</td>\n","      <td>2014-07-01</td>\n","      <td>0.960770</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>19</td>\n","      <td>2014-08-01</td>\n","      <td>0.956339</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Unnamed: 0           0         1\n","0            0  2014-09-01  0.954463\n","1            1  2014-10-01  0.973430\n","2            2  2014-11-01  0.967619\n","3            3  2014-12-01  0.966987\n","4            4  2015-01-01  0.969573\n","5            5  2015-02-01  0.963006\n","6            6  2015-03-01  0.955877\n","7            7  2015-04-01  0.964053\n","8            8  2015-05-01  0.973276\n","9            9  2015-06-01  0.965090\n","10          10  2015-07-01  0.960453\n","11          11  2015-08-01  0.967825\n","12          12  2015-09-01  0.966486\n","13          13  2015-10-01  0.978070\n","14          14  2015-11-01  0.971703\n","15          15  2015-12-01  0.972356\n","16          16  2016-01-01  0.972522\n","17          17  2016-02-01  0.959797\n","18          18  2016-03-01  0.958413\n","19          19  2016-04-01  0.975944\n","20          20  2016-05-01  0.972383\n","21          21  2016-06-01  0.975523\n","22          22  2016-07-01  0.969961\n","23          23  2016-08-01  0.974454\n","24          24  2016-09-01  0.973805\n","25          25  2016-10-01  0.980590\n","26          26  2016-11-01  0.977438\n","27          27  2016-12-01  0.960286\n","0            0  2013-01-01  0.964434\n","1            1  2013-02-01  0.958117\n","2            2  2013-03-01  0.957099\n","3            3  2013-04-01  0.962764\n","4            4  2013-05-01  0.968763\n","5            5  2013-06-01  0.965812\n","6            6  2013-07-01  0.963463\n","7            7  2013-08-01  0.960850\n","8            8  2013-09-01  0.960586\n","9            9  2013-10-01  0.968932\n","10          10  2013-11-01  0.959499\n","11          11  2013-12-01  0.955507\n","12          12  2014-01-01  0.965953\n","13          13  2014-02-01  0.960077\n","14          14  2014-03-01  0.956442\n","15          15  2014-04-01  0.960666\n","16          16  2014-05-01  0.964631\n","17          17  2014-06-01  0.952294\n","18          18  2014-07-01  0.960770\n","19          19  2014-08-01  0.956339"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"r8oTUGZOePwR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1595991059291,"user_tz":180,"elapsed":949,"user":{"displayName":"Lucas Almada","photoUrl":"","userId":"05667266763048656725"}},"outputId":"4737f95c-74d5-4704-a867-331eb3073781"},"source":["fig = go.Figure()\n","fig.add_trace(go.Scatter(x=df_total['0'], y=df_total['1'], name = 'Similaridade Tweets-Notícias'))\n","fig.update_xaxes(rangeslider_visible=True)\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"70fb189d-1d85-48a5-9f1a-bdb71d8deaf0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"70fb189d-1d85-48a5-9f1a-bdb71d8deaf0\")) {\n","                    Plotly.newPlot(\n","                        '70fb189d-1d85-48a5-9f1a-bdb71d8deaf0',\n","                        [{\"name\": \"Similaridade Tweets-Not\\u00edcias\", \"type\": \"scatter\", \"x\": [\"2013-01-01\", \"2013-02-01\", \"2013-03-01\", \"2013-04-01\", \"2013-05-01\", \"2013-06-01\", \"2013-07-01\", \"2013-08-01\", \"2013-09-01\", \"2013-10-01\", \"2013-11-01\", \"2013-12-01\", \"2014-01-01\", \"2014-02-01\", \"2014-03-01\", \"2014-04-01\", \"2014-05-01\", \"2014-06-01\", \"2014-07-01\", \"2014-08-01\", \"2014-09-01\", \"2014-10-01\", \"2014-11-01\", \"2014-12-01\", \"2015-01-01\", \"2015-02-01\", \"2015-03-01\", \"2015-04-01\", \"2015-05-01\", \"2015-06-01\", \"2015-07-01\", \"2015-08-01\", \"2015-09-01\", \"2015-10-01\", \"2015-11-01\", \"2015-12-01\", \"2016-01-01\", \"2016-02-01\", \"2016-03-01\", \"2016-04-01\", \"2016-05-01\", \"2016-06-01\", \"2016-07-01\", \"2016-08-01\", \"2016-09-01\", \"2016-10-01\", \"2016-11-01\", \"2016-12-01\"], \"y\": [0.964434305284138, 0.9581168517861144, 0.9570993046068804, 0.9627641182947596, 0.9687631415538129, 0.9658119512228532, 0.9634632934614632, 0.9608499111602796, 0.9605860291808253, 0.9689317521770688, 0.9594989082100054, 0.9555072236337474, 0.9659527778833642, 0.9600773081281476, 0.956441798758342, 0.9606661090581526, 0.9646306922399396, 0.9522939128571534, 0.9607699603479676, 0.9563390767660508, 0.9544629985807004, 0.9734296318304341, 0.9676191558767904, 0.9669866669416116, 0.9695727490422452, 0.9630061524506924, 0.9558772567161024, 0.964053305506308, 0.9732763567135236, 0.9650903654682218, 0.9604532929363109, 0.9678251169995264, 0.966485761486208, 0.9780702392920172, 0.9717033873338756, 0.9723560512949712, 0.9725223747074072, 0.9597965337780502, 0.9584127368716164, 0.9759435190060208, 0.9723825230730052, 0.9755233960855124, 0.9699610650000524, 0.9744540976596824, 0.9738047511436584, 0.9805897459497318, 0.9774379939500912, 0.9602856892830084]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"rangeslider\": {\"visible\": true}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('70fb189d-1d85-48a5-9f1a-bdb71d8deaf0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"T0wc5AwFeqlK","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}